# Optional: LLM extraction provider
# Set LLM_PROVIDER to "openai" or "ollama" or leave unset to disable LLM extraction.
LLM_PROVIDER=openai

# For OpenAI-compatible endpoints:
OPENAI_API_KEY=your_key_here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4o-mini

# For Ollama (local):
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# API settings
APP_LOG_LEVEL=INFO
